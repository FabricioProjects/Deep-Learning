{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:09:40.145536",
     "start_time": "2017-07-26T14:09:40.131525"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016-2017 by Fabricio Amaral. All Rights Reserved.\n",
    "# Permission to use, copy, modify, and distribute this software and its\n",
    "# documentation for any purpose and without fee is hereby granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:17:46.643195",
     "start_time": "2017-07-26T14:17:05.712798"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:17:56.624754",
     "start_time": "2017-07-26T14:17:49.332991"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "y = numpy.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:22:39.438184",
     "start_time": "2017-07-26T14:22:39.429690"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "<class 'numpy.ndarray'> (50000,)\n",
      "<class 'numpy.ndarray'> (50000,)\n"
     ]
    }
   ],
   "source": [
    "# summarize size\n",
    "print(\"Training data: \")\n",
    "print(type(X), X.shape)\n",
    "print(type(y), y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:19:09.746929",
     "start_time": "2017-07-26T14:19:09.734037"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that it is a binary classification problem for good and bad sentiment in the review.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:02:38.057159",
     "start_time": "2017-05-29T19:02:38.030167"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of classes\n",
    "print(\"Classes: \")\n",
    "print(numpy.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:05:21.071663",
     "start_time": "2017-05-29T19:05:18.917370"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of words\n",
    "# numpy.hstack(X) :Take a sequence of arrays and stack them horizontally to make a single array.\n",
    "print(\"Number of words: \")\n",
    "print(len(numpy.unique(numpy.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:11:46.010806",
     "start_time": "2017-05-29T19:11:43.918584"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     4, ..., 88584, 88585, 88586])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.unique(numpy.hstack(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:23:16.610507",
     "start_time": "2017-05-29T19:23:16.164467"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65a310f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:22:13.880668",
     "start_time": "2017-05-29T19:22:13.850850"
    }
   },
   "source": [
    "**Let’s say that we are only interested in the first 5,000 most used words in the dataset. Therefore our vocabulary size will be 5,000. We can choose to use a 32-dimension vector to represent each word. Finally, we may choose to cap the maximum review length at 500 words, truncating reviews longer than that and padding reviews shorter than that with 0 values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:54:50.449907",
     "start_time": "2017-05-29T19:54:43.915385"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb.load_data(nb_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:55:01.853224",
     "start_time": "2017-05-29T19:55:01.763980"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP for the IMDB problem\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T19:57:13.326446",
     "start_time": "2017-05-29T19:57:04.042350"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output of this first layer will be a 32×500 sized matrix. We will flatten the Embedded layers output to one dimension, then use one dense hidden layer of 250 units with a rectifier activation function. The output layer has one neuron and will use a sigmoid activation to output values of 0 and 1 as predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T20:03:15.542149",
     "start_time": "2017-05-29T20:03:14.937443"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model overfits very quickly so we will use very few training epochs, in this case just 2.\n",
    "There is a lot of data so we will use a batch size of 128. After the model is trained, we evaluate its accuracy on the test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T20:09:23.236669",
     "start_time": "2017-05-29T20:07:37.148603"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "50s - loss: 0.5184 - acc: 0.7069 - val_loss: 0.2986 - val_acc: 0.8715\n",
      "Epoch 2/2\n",
      "46s - loss: 0.1916 - acc: 0.9260 - val_loss: 0.3099 - val_acc: 0.8714\n",
      "Accuracy: 87.14%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Dimensional Convolutional Neural Network Model for the IMDB Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The same properties that make the CNN model attractive for learning to recognize objects in images can help to learn structure in paragraphs of words, namely the techniques invariance to the specific position of features.\n",
    "Keras supports one-dimensional convolutions and pooling by the Conv1D and MaxPooling1D classes respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T20:20:22.782206",
     "start_time": "2017-05-29T20:20:22.758634"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN for the IMDB problem\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T20:21:07.859663",
     "start_time": "2017-05-29T20:20:59.098927"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# pad dataset to a maximum review length in words\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can now define our convolutional neural network model. This time, after the Embedding input layer, we insert a Conv1D layer. This convolutional layer has 32 feature maps and reads embedded word representations 3 vector elements of the word embedding at a time.\n",
    "The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T20:23:43.145221",
     "start_time": "2017-05-29T20:23:42.952629"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T20:26:55.782573",
     "start_time": "2017-05-29T20:25:06.589370"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "48s - loss: 0.4488 - acc: 0.7603 - val_loss: 0.3167 - val_acc: 0.8643\n",
      "Epoch 2/2\n",
      "48s - loss: 0.2391 - acc: 0.9066 - val_loss: 0.2956 - val_acc: 0.8768\n",
      "Accuracy: 87.68%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
